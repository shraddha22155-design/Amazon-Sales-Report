{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f803a6e6",
   "metadata": {},
   "source": [
    "# Amazon Sales Report — End‑to‑End Analysis\n",
    "Run the cells below to reproduce the analysis, KPIs, and charts. (Matplotlib only; no seaborn.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404664cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import parser as dtparser\n",
    "\n",
    "csv_path = Path('/mnt/data/Amazon Sale Report (1).csv')  # adjust if needed\n",
    "out_dir = Path('/mnt/data/amazon_sales_output')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_lower_strip(s):\n",
    "    if pd.isna(s): return s\n",
    "    return str(s).strip()\n",
    "\n",
    "def parse_date_safe(x):\n",
    "    if pd.isna(x): return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(dtparser.parse(str(x), dayfirst=False))\n",
    "    except Exception:\n",
    "        try:\n",
    "            return pd.to_datetime(x, errors='coerce')\n",
    "        except Exception:\n",
    "            return pd.NaT\n",
    "\n",
    "def to_number(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int,float,np.number)): return float(x)\n",
    "    s = str(x).replace(',', '').replace('₹','').replace('$','').replace('€','').strip()\n",
    "    try: return float(s)\n",
    "    except Exception: return np.nan\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "date_col = 'Date' if 'Date' in df.columns else None\n",
    "if date_col:\n",
    "    df['parsed_date'] = df[date_col].apply(parse_date_safe)\n",
    "    df['order_date'] = df['parsed_date'].dt.date\n",
    "    df['year'] = df['parsed_date'].dt.year\n",
    "    df['month'] = df['parsed_date'].dt.to_period('M').astype(str)\n",
    "    df['week'] = df['parsed_date'].dt.to_period('W').astype(str)\n",
    "else:\n",
    "    df['parsed_date'] = pd.NaT\n",
    "\n",
    "df['Qty_num'] = pd.to_numeric(df.get('Qty', np.nan), errors='coerce')\n",
    "df['Amount_num'] = pd.Series(df.get('Amount', np.nan)).apply(to_number)\n",
    "\n",
    "for col in ['Status','Fulfilment','Sales Channel','Category','Size','Courier Status',\n",
    "            'ship-city','ship-state','ship-country','currency','B2B','fulfilled-by']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(_safe_lower_strip)\n",
    "\n",
    "def status_bucket(s):\n",
    "    if pd.isna(s): return 'unknown'\n",
    "    s = s.lower()\n",
    "    if any(k in s for k in ['cancel','refunded','return']): return 'non_revenue'\n",
    "    if any(k in s for k in ['pending','on-hold']): return 'pending'\n",
    "    return 'completed'\n",
    "\n",
    "df['status_bucket'] = df.get('Status', 'completed')\n",
    "if 'Status' in df.columns:\n",
    "    df['status_bucket'] = df['Status'].apply(status_bucket)\n",
    "else:\n",
    "    df['status_bucket'] = 'completed'\n",
    "\n",
    "df['gross_revenue'] = df['Amount_num'].fillna(0.0)\n",
    "df['units'] = df['Qty_num'].fillna(0.0)\n",
    "df['net_revenue'] = np.where(df['status_bucket'].eq('completed'), df['gross_revenue'], 0.0)\n",
    "df['order_id'] = df.get('Order ID', pd.Series(range(len(df)))).astype(str)\n",
    "\n",
    "df.to_csv(out_dir/'cleaned_sales.csv', index=False)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f737281",
   "metadata": {},
   "source": [
    "## KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a61c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed = df[df['status_bucket'].eq('completed')]\n",
    "kpis = {\n",
    "    'total_orders': completed['order_id'].nunique(),\n",
    "    'total_units': float(completed['units'].sum()),\n",
    "    'gross_revenue': float(df['gross_revenue'].sum()),\n",
    "    'net_revenue': float(completed['net_revenue'].sum()),\n",
    "    'avg_order_value': float(completed.groupby('order_id')['net_revenue'].sum().mean() if len(completed) else 0.0),\n",
    "    'avg_selling_price': float((completed['net_revenue'].sum() / completed['units'].sum()) if completed['units'].sum() > 0 else 0.0),\n",
    "    'return_cancel_rate_%': float(100.0 * (df['status_bucket'].eq('non_revenue').sum() / len(df)) if len(df) else 0.0)\n",
    "}\n",
    "kpis_df = pd.DataFrame([kpis])\n",
    "kpis_df.to_csv(out_dir/'kpis.csv', index=False)\n",
    "kpis_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8513c38",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cda68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df['parsed_date'].isna().all():\n",
    "    print(\"No valid dates available for time series.\")\n",
    "else:\n",
    "    daily = completed.groupby('order_date').agg(net_revenue=('net_revenue','sum'),\n",
    "                                                units=('units','sum'),\n",
    "                                                orders=('order_id','nunique')).reset_index()\n",
    "    monthly = completed.groupby('month').agg(net_revenue=('net_revenue','sum'),\n",
    "                                             units=('units','sum'),\n",
    "                                             orders=('order_id','nunique')).reset_index()\n",
    "    daily.to_csv(out_dir/'ts_daily.csv', index=False)\n",
    "    monthly.to_csv(out_dir/'ts_monthly.csv', index=False)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.plot(pd.to_datetime(daily['order_date']), daily['net_revenue'])\n",
    "    plt.title('Daily Net Revenue'); plt.xlabel('Date'); plt.ylabel('Net Revenue')\n",
    "    plt.tight_layout(); plt.savefig(out_dir/'ts_daily_net_revenue.png'); plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.bar(pd.to_datetime(monthly['month'].astype(str)), monthly['net_revenue'])\n",
    "    plt.title('Monthly Net Revenue'); plt.xlabel('Month'); plt.ylabel('Net Revenue')\n",
    "    plt.tight_layout(); plt.savefig(out_dir/'ts_monthly_net_revenue.png'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914c7f7",
   "metadata": {},
   "source": [
    "## Categorical Breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "breakdowns = {}\n",
    "for col in ['Category','Size','Fulfilment','Sales Channel','ship-city','ship-state','ship-country','Courier Status','currency','fulfilled-by','B2B']:\n",
    "    if col in df.columns:\n",
    "        tmp = completed.groupby(col).agg(net_revenue=('net_revenue','sum'),\n",
    "                                         units=('units','sum'),\n",
    "                                         orders=('order_id','nunique')).reset_index().sort_values('net_revenue', ascending=False)\n",
    "        breakdowns[col] = tmp\n",
    "        tmp.to_csv(out_dir / f\"by_{col.replace(' ', '_').replace('-', '_')}.csv\", index=False)\n",
    "        head = tmp.head(10)\n",
    "        plt.figure()\n",
    "        plt.bar(head[col].astype(str), head['net_revenue'])\n",
    "        plt.title(f\"Top {min(10, len(head))} by {col} — Net Revenue\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout(); plt.savefig(out_dir / f\"by_{col.replace(' ', '_').replace('-', '_')}_top10.png\"); plt.show()\n",
    "        \n",
    "list(breakdowns.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cd1eb",
   "metadata": {},
   "source": [
    "## RFM-like Segmentation (city/state proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if {'ship-city','ship-state','parsed_date'}.issubset(df.columns) and not df['parsed_date'].isna().all():\n",
    "    now = df.loc[df['status_bucket'].eq('completed'),'parsed_date'].max() + pd.Timedelta(days=1)\n",
    "    completed2 = df[df['status_bucket'].eq('completed') & df['parsed_date'].notna()].copy()\n",
    "    key = completed2[['ship-city','ship-state']].fillna('unknown').agg('|'.join, axis=1)\n",
    "    grp = completed2.assign(segment=key).groupby('segment')\n",
    "    r = grp['parsed_date'].max().apply(lambda d: (now - d).days)\n",
    "    f = grp['order_id'].nunique()\n",
    "    m = grp['net_revenue'].sum()\n",
    "    rfm = pd.DataFrame({'R': r, 'F': f, 'M': m}).reset_index()\n",
    "    \n",
    "    rfm['R_score'] = pd.qcut(-rfm['R'].rank(method='first'), 5, labels=[1,2,3,4,5]).astype(int)\n",
    "    rfm['F_score'] = pd.qcut(rfm['F'].rank(method='first'), 5, labels=[1,2,3,4,5]).astype(int)\n",
    "    rfm['M_score'] = pd.qcut(rfm['M'].rank(method='first'), 5, labels=[1,2,3,4,5]).astype(int)\n",
    "    rfm['RFM_total'] = rfm[['R_score','F_score','M_score']].sum(axis=1)\n",
    "    def bucket(total):\n",
    "        if total >= 13: return 'Champions'\n",
    "        if total >= 10: return 'Loyal/High-Value'\n",
    "        if total >= 7: return 'Potential Loyalist'\n",
    "        if total >= 5: return 'Needs Attention'\n",
    "        return 'At Risk'\n",
    "    rfm['Segment'] = rfm['RFM_total'].apply(bucket)\n",
    "    rfm.to_csv(out_dir/'rfm_segments.csv', index=False)\n",
    "    \n",
    "    counts = rfm['Segment'].value_counts().reset_index()\n",
    "    plt.figure()\n",
    "    plt.bar(counts['index'].astype(str), counts['Segment'])\n",
    "    plt.title('RFM Segment Distribution'); plt.xticks(rotation=30, ha='right')\n",
    "    plt.tight_layout(); plt.savefig(out_dir/'rfm_segment_distribution.png'); plt.show()\n",
    "else:\n",
    "    print(\"Not enough fields for RFM proxy segmentation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6289fd",
   "metadata": {},
   "source": [
    "## Save quick insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "insights = []\n",
    "insights.append(f\"Total Net Revenue: {kpis['net_revenue']:.2f}\")\n",
    "insights.append(f\"Total Orders: {kpis['total_orders']} | Units: {kpis['total_units']:.0f}\")\n",
    "insights.append(f\"AOV: {kpis['avg_order_value']:.2f} | ASP: {kpis['avg_selling_price']:.2f}\")\n",
    "insights.append(f\"Return/Cancel Rate: {kpis['return_cancel_rate_%']:.2f}%\")\n",
    "\n",
    "if 'month' in df.columns and not df['parsed_date'].isna().all():\n",
    "    monthly = completed.groupby('month')['net_revenue'].sum().reset_index().sort_values('net_revenue', ascending=False)\n",
    "    if not monthly.empty:\n",
    "        insights.append(f\"Best Month by Net Revenue: {monthly.iloc[0]['month']}\")\n",
    "\n",
    "if 'Category' in df.columns and 'net_revenue' in df.columns:\n",
    "    cat = breakdowns.get('Category')\n",
    "    if cat is not None and not cat.empty:\n",
    "        insights.append(f\"Top Category: {cat.iloc[0]['Category']} — {cat.iloc[0]['net_revenue']:.2f} net revenue\")\n",
    "\n",
    "if 'ship-state' in df.columns:\n",
    "    state = breakdowns.get('ship-state')\n",
    "    if state is not None and not state.empty:\n",
    "        insights.append(f\"Top State: {state.iloc[0]['ship-state']} — {state.iloc[0]['net_revenue']:.2f} net revenue\")\n",
    "\n",
    "(Path('/mnt/data/amazon_sales_output') / 'insights.txt').write_text(\"\\n\".join(insights), encoding='utf-8')\n",
    "insights\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
